import streamlit as st
import re
import os
import time
from dotenv import load_dotenv

# [Import] src í´ë” ë‚´ì˜ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš” (ì˜ˆ: from src.toxic_detector import ...)
from toxic_detector import ToxicClauseDetector
from ollama_detctor import ToxicClauseDetectorOllama
from llm_service import LLM_gemini

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="SafeSign - On-Device AI",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. í—¬í¼ í•¨ìˆ˜ë“¤ ---

def extract_text_from_pdf(pdf_file, api_key): 
    """
    [OCR] PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì€ ì„±ëŠ¥ì´ ì¢‹ì€ Gemini Visionì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    (Ollama Llama3ëŠ” Vision ê¸°ëŠ¥ì´ ì—†ê±°ë‚˜ ì•½í•˜ê¸° ë•Œë¬¸)
    """
    try:
        pdf_file_bytes = pdf_file.read()   
        # Gemini 1.5 Flashê°€ OCR ê°€ì„±ë¹„ê°€ ì¢‹ìŒ
        gemini = LLM_gemini(gemini_api_key=api_key, model='gemini-2.5-flash')
        result = gemini.pdf_to_text(pdf_file_bytes)
        return result
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def get_dummy_contract_text():
    return """
ì œ1ì¡° (ëª©ì ) ë³¸ ê³„ì•½ì€ ì‚¬ìš©ì (ì£¼)ì•…ë•ìƒì‚¬(ì´í•˜ "ê°‘")ì™€ ê·¼ë¡œì í™ê¸¸ë™(ì´í•˜ "ì„")ì˜ ê·¼ë¡œì¡°ê±´ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.
ì œ2ì¡° (ê·¼ë¡œì‹œê°„) ê·¼ë¡œì‹œê°„ì€ 09:00ë¶€í„° 18:00ê¹Œì§€ë¡œ í•œë‹¤. "ê°‘"ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ê²½ìš° "ì„"ì—ê²Œ ì—°ì¥ê·¼ë¡œë¥¼ ëª…í•  ìˆ˜ ìˆìœ¼ë©° "ì„"ì€ ì´ì— í¬ê´„ì ìœ¼ë¡œ ë™ì˜í•œë‹¤.
ì œ3ì¡° (ì„ê¸ˆ) ì›” ê¸‰ì—¬ëŠ” 250ë§Œì›ìœ¼ë¡œ í•˜ë©°, ì´ëŠ” ì—°ì¥/ì•¼ê°„/íœ´ì¼ ê·¼ë¡œìˆ˜ë‹¹ì„ ëª¨ë‘ í¬í•¨í•œ í¬ê´„ì„ê¸ˆìœ¼ë¡œ í•œë‹¤.
ì œ4ì¡° (í‡´ì§ê¸ˆ) 1ë…„ ë¯¸ë§Œ ê·¼ë¬´ ì‹œ í‡´ì§ê¸ˆì€ ì§€ê¸‰í•˜ì§€ ì•Šìœ¼ë©°, í‡´ì‚¬ ì‹œ êµìœ¡ë¹„ ëª…ëª©ìœ¼ë¡œ 300ë§Œì›ì„ ë°°ìƒí•œë‹¤.
ì œ5ì¡° (í•´ê³ ) "ê°‘"ì€ "ì„"ì˜ ì—…ë¬´ ì„±ê³¼ê°€ ì €ì¡°í•˜ë‹¤ê³  íŒë‹¨ë  ê²½ìš° ì¦‰ì‹œ í•´ê³ í•  ìˆ˜ ìˆë‹¤.
"""

def parse_text_to_chunks(text):
    if not text: return []
    split_pattern = r'(?=\n\s*ì œ\s*\d+\s*ì¡°)'
    chunks = re.split(split_pattern, text)
    return [c.strip() for c in chunks if len(c.strip()) > 10]

# --- 3. ë©”ì¸ ì–´í”Œë¦¬ì¼€ì´ì…˜ --- 
def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("ğŸ›¡ï¸ SafeSign Local")
        st.caption("On-Device Analysis with Ollama")
        st.markdown("---")
        
        load_dotenv()
        env_key = os.getenv("GEMINI_API_KEY")
        
        # 1. OCRìš© API í‚¤ (í•„ìˆ˜ ì•„ë‹˜, ì—†ìœ¼ë©´ ë”ë¯¸ ì‚¬ìš©)
        api_key_input = st.text_input(
            "Gemini API Key (OCRìš©)", 
            value=env_key if env_key else "", 
            type="password",
            help="PDF ì´ë¯¸ì§€ ì¸ì‹ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤."
        )
        
        # 2. Ollama ëª¨ë¸ ì„ íƒ
        ollama_model = st.selectbox(
            "Ollama Model", 
            ["llama3", "mistral", "gemma", "hf.co/LiquidAI/LFM2-8B-A1B-GGUF:Q4_K_M"],
            index=0
        )

        st.info(f"ğŸ’¡ ë¶„ì„ ì—”ì§„: Local {ollama_model}\n(ë‚´ ì»´í“¨í„°ì˜ GPU/CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤)")

    # ë©”ì¸ í™”ë©´
    st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸° (Local Ver.)")
    st.markdown("ë³´ì•ˆì´ ì¤‘ìš”í•œ ê³„ì•½ì„œ, **ì™¸ë¶€ ì„œë²„ ì „ì†¡ ì—†ì´** ë‚´ ì»´í“¨í„°ì˜ Ollamaê°€ ì§ì ‘ ë¶„ì„í•©ë‹ˆë‹¤.")

    # íŒŒì¼ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¡œë”©
    uploaded_file = st.file_uploader("ê·¼ë¡œê³„ì•½ì„œ PDF ì—…ë¡œë“œ", type=["pdf"])
    
    contract_content = ""
    
    if uploaded_file is not None:
        if api_key_input:
            with st.spinner("ğŸ‘€ Geminiê°€ ë¬¸ì„œë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤ (OCR)..."):
                extracted_text = extract_text_from_pdf(uploaded_file, api_key_input)
                if extracted_text:
                    contract_content = extracted_text
                    st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
                else:
                    contract_content = get_dummy_contract_text()
                    st.warning("ì¶”ì¶œ ì‹¤íŒ¨. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            st.warning("OCRìš© API í‚¤ê°€ ì—†ì–´ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            contract_content = get_dummy_contract_text()
    else:
        contract_content = get_dummy_contract_text()

    # í…ìŠ¤íŠ¸ ì—ë””í„°
    final_text = st.text_area("ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸", value=contract_content, height=300)

    # [ë¶„ì„ ë²„íŠ¼]
    if st.button("ğŸš€ ë¡œì»¬ AI ë¶„ì„ ì‹œì‘", use_container_width=True):
        
        # 1. Parsing
        chunks = parse_text_to_chunks(final_text)
        if not chunks:
            st.error("ë¶„ì„í•  ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        # 2. Detector ì´ˆê¸°í™” (Ollama)
        # ë¡œì»¬ ëª¨ë¸ ë¡œë”©ì€ ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ ìºì‹± í•„ìˆ˜
        @st.cache_resource
        def get_ollama_detector(model_name):
            return ToxicClauseDetectorOllama(model_name=model_name)
        
        with st.spinner(f"âš™ï¸ Ollama({ollama_model}) ëª¨ë¸ ë° ë²•ë¥  DB ë¡œë”© ì¤‘..."):
            try:
                detector = get_ollama_detector(ollama_model)
            except Exception as e:
                st.error(f"Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
                st.info("í„°ë¯¸ë„ì—ì„œ 'ollama serve'ê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                st.stop()

        st.info(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­ì„ ë¶„ì„í•©ë‹ˆë‹¤. (ë¡œì»¬ ëª¨ë¸ íŠ¹ì„±ìƒ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

        # 3. ë¶„ì„ ì‹¤í–‰ (ìˆœì°¨ ì²˜ë¦¬ ê¶Œì¥)
        # OllamaëŠ” ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ê°€ ì•½í•˜ë¯€ë¡œ max_concurrent=1 ì„¤ì •
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        processed_results = []
        
        try:
            # detect í•¨ìˆ˜ê°€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬í•¨
            raw_results = detector.detect(chunks, max_concurrent=1)
            
            # ê²°ê³¼ ê°€ê³µ ë° ì œì•ˆ ìƒì„±
            for i, res in enumerate(raw_results):
                res['id'] = i + 1
                res['suggestion'] = ""
                
                # [ìˆ˜ì •] ë…ì†Œì¡°í•­ì¸ ê²½ìš° ìë™ìœ¼ë¡œ ì œì•ˆ(ì‰¬ìš´ í•´ì„) ìƒì„±
                if res['is_toxic']:
                    status_text.text(f"âš ï¸ ì œ{i+1}ì¡° ë¶„ì„ ì¤‘... (ê°œì„ ì•ˆ ìƒì„± í¬í•¨)")
                    try:
                        res['suggestion'] = detector.generate_easy_suggestion(res)
                    except Exception:
                        res['suggestion'] = "ì œì•ˆ ìƒì„± ì‹¤íŒ¨"
                
                processed_results.append(res)
                progress_bar.progress((i + 1) / len(chunks))
                
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

        status_text.empty()
        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
        
        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        st.divider()
        
        toxic_indices = [i for i, r in enumerate(processed_results) if r['is_toxic']]
        
        col1, col2 = st.columns(2)
        col1.metric("ë¶„ì„ëœ ì¡°í•­", f"{len(chunks)}ê±´")
        col2.metric("ìœ„í—˜ ì¡°í•­ ë°œê²¬", f"{len(toxic_indices)}ê±´", delta="-ì£¼ì˜" if toxic_indices else "ì•ˆì „")

        # ìƒì„¸ ê²°ê³¼ íƒ­
        tab1, tab2 = st.tabs(["ğŸš¨ ìœ„í—˜ ì¡°í•­ ë¦¬í¬íŠ¸", "ğŸ“‘ ì „ì²´ ì¡°í•­ ë³´ê¸°"])
        
        with tab1:
            if not toxic_indices:
                st.balloons()
                st.success("ë°œê²¬ëœ ë…ì†Œì¡°í•­ì´ ì—†ìŠµë‹ˆë‹¤!")
            else:
                for idx in toxic_indices:
                    res = processed_results[idx]
                    
                    with st.expander(f"âš ï¸ [ìœ„í—˜] ì œ{res['id']}ì¡° (ìœ„í—˜ë„: {res['risk_score']})", expanded=True):
                        c1, c2 = st.columns(2)
                        with c1:
                            st.caption("âŒ ì›ë¬¸")
                            st.error(res['clause'])
                            st.markdown(f"**ğŸ” íŒë‹¨ ê·¼ê±°:**\n{res['reason']}")
                        with c2:
                            st.caption("ğŸ’¡ AI ìˆ˜ì • ì œì•ˆ & ì‰¬ìš´ í•´ì„")
                            # [ìˆ˜ì •] ë²„íŠ¼ ì—†ì´ ë°”ë¡œ ë‚´ìš© í‘œì‹œ
                            if res['suggestion']:
                                st.markdown(res['suggestion'])
                            else:
                                st.info("ì œì•ˆ ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            
                            with st.popover("ì°¸ê³  ë²•ë ¹ ë³´ê¸°"):
                                st.text(res['context_used'])
        
        with tab2:
            for res in processed_results:
                icon = "ğŸ”´" if res['is_toxic'] else "ğŸŸ¢"
                with st.expander(f"{icon} ì œ{res['id']}ì¡°"):
                    st.write(res['clause'])
                    st.caption(f"íŒë‹¨: {res['reason']}")

if __name__ == "__main__":
    main()