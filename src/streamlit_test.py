import streamlit as st
import re
import os
import time
from dotenv import load_dotenv

# [Import] src í´ë” ë‚´ì˜ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from toxic_detector import ToxicClauseDetector
from llm_service import LLM_gemini

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸°",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. í—¬í¼ í•¨ìˆ˜ë“¤ (PDF íŒŒì‹± & ë”ë¯¸ ë°ì´í„°) ---

def extract_text_from_pdf(pdf_file,api_key,model_name): 
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    pdf_file_bytes = pdf_file.read()   
    gemini = LLM_gemini(gemini_api_key=api_key, model=model_name)
    result = gemini.pdf_to_text(pdf_file_bytes)
    return result

def get_dummy_contract_text():
    """í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ê·¼ë¡œê³„ì•½ì„œ í…ìŠ¤íŠ¸"""
    return """
ì œ1ì¡° (ëª©ì )
ë³¸ ê³„ì•½ì€ ì‚¬ìš©ì (ì£¼)ì•…ë•ìƒì‚¬(ì´í•˜ "ê°‘")ì™€ ê·¼ë¡œì í™ê¸¸ë™(ì´í•˜ "ì„")ì˜ ê·¼ë¡œì¡°ê±´ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.

ì œ2ì¡° (ê·¼ë¡œì¥ì†Œ ë° ì—…ë¬´)
"ì„"ì€ "ê°‘"ì˜ ë³¸ì‚¬ ë° "ê°‘"ì´ ì§€ì •í•˜ëŠ” ì¥ì†Œì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤.

ì œ3ì¡° (ê·¼ë¡œì‹œê°„)
1. ê·¼ë¡œì‹œê°„ì€ 09:00ë¶€í„° 18:00ê¹Œì§€ë¡œ í•œë‹¤ (íœ´ê²Œì‹œê°„ 1ì‹œê°„ í¬í•¨).
2. "ê°‘"ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ê²½ìš° "ì„"ì—ê²Œ ì—°ì¥, ì•¼ê°„ ë° íœ´ì¼ê·¼ë¡œë¥¼ ëª…í•  ìˆ˜ ìˆìœ¼ë©° "ì„"ì€ ì´ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.

ì œ4ì¡° (ì„ê¸ˆ)
1. ì›” ê¸‰ì—¬ëŠ” 2,500,000ì›ìœ¼ë¡œ í•œë‹¤.
2. ìœ„ ê¸‰ì—¬ì—ëŠ” ì‹ëŒ€, êµí†µë¹„ ë° ë²•ì • ì œìˆ˜ë‹¹(ì—°ì¥, ì•¼ê°„, íœ´ì¼ê·¼ë¡œìˆ˜ë‹¹ ë“±)ì´ ëª¨ë‘ í¬í•¨ëœ í¬ê´„ì„ê¸ˆìœ¼ë¡œ ì‚°ì •í•˜ë©°, "ì„"ì€ ì¶”ê°€ì ì¸ ìˆ˜ë‹¹ì„ ì²­êµ¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì œ5ì¡° (í‡´ì§ê¸ˆ)
"ì„"ì´ ì…ì‚¬ í›„ 1ë…„ ë¯¸ë§Œì— í‡´ì‚¬í•˜ëŠ” ê²½ìš°, ìˆ˜ìŠµê¸°ê°„ ë™ì•ˆì˜ êµìœ¡ë¹„ ë° ì†í•´ë°°ìƒ ëª…ëª©ìœ¼ë¡œ í‡´ì§ê¸ˆì€ ì§€ê¸‰í•˜ì§€ ì•„ë‹ˆí•œë‹¤.

ì œ6ì¡° (ê³„ì•½í•´ì§€)
"ì„"ì´ ë¬´ë‹¨ê²°ê·¼ 3ì¼ ì´ìƒ ì§€ì†í•˜ê±°ë‚˜ ì—…ë¬´ ëŠ¥ë ¥ì´ í˜„ì €íˆ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë  ê²½ìš° "ê°‘"ì€ ì¦‰ì‹œ ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆë‹¤.

ì œ7ì¡° (ì†í•´ë°°ìƒ)
"ì„"ì´ ê³„ì•½ê¸°ê°„ ì¤‘ í‡´ì‚¬í•˜ì—¬ "ê°‘"ì—ê²Œ ì†í•´ë¥¼ ì…íŒ ê²½ìš°, "ì„"ì€ "ê°‘"ì—ê²Œ ì¼ê¸ˆ 1,000ë§Œì›ì„ ë°°ìƒí•˜ì—¬ì•¼ í•œë‹¤.
"""

def parse_text_to_chunks(text):
    """í…ìŠ¤íŠ¸ë¥¼ 'ì œNì¡°' ê¸°ì¤€ìœ¼ë¡œ ìë¥´ëŠ” íŒŒì„œ"""
    if not text:
        return []
    split_pattern = r'(?=\n\s*ì œ\s*\d+\s*ì¡°)'
    chunks = re.split(split_pattern, text)
    # ê³µë°± ì œê±° ë° ìœ íš¨í•œ ì¡°í•­ë§Œ í•„í„°ë§
    clean_chunks = [c.strip() for c in chunks if len(c.strip()) > 10]
    return clean_chunks

def process_single_clause(detector, clause, index):
    """ë‹¨ìœ„ ì‘ì—…: ì¡°í•­ í•˜ë‚˜ ë¶„ì„"""
    try:
        detection = detector.detect(clause)
        
        suggestion = ""
        if detection['is_toxic']:
            suggestion = detector.generate_easy_suggestion(detection)
            
        return {
            "id": index + 1,
            "clause": clause,
            "is_toxic": detection['is_toxic'],
            "score": detection['risk_score'],
            "reason": detection['reason'],
            "context": detection['context_used'],
            "suggestion": suggestion,
            "status": "success"
        }
    except Exception as e:
        return {
            "id": index + 1,
            "clause": clause,
            "error": str(e),
            "status": "error"
        }

# --- 3. ë©”ì¸ ì–´í”Œë¦¬ì¼€ì´ì…˜ --- 
def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("âš–ï¸ Contract Guardian")
        st.markdown("---")
        
        load_dotenv()
        env_key = os.getenv("GEMINI_API_KEY")
        
        api_key_input = st.text_input(
            "Gemini API Key", 
            value=env_key if env_key else "", 
            type="password"
        )
        if api_key_input:
            os.environ["GEMINI_API_KEY"] = api_key_input

        st.info("ğŸ’¡ PDF íŒŒì¼ì„ ì˜¬ë¦¬ë©´ í•´ë‹¹ ë‚´ìš©ì„, ì˜¬ë¦¬ì§€ ì•Šìœ¼ë©´ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    # ë©”ì¸ í™”ë©´
    st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸°")
    st.markdown("ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‚´ìš©ì„ ì§ì ‘ ì…ë ¥í•˜ë©´ AIê°€ **ë…ì†Œì¡°í•­**ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.")

    # --- [í•µì‹¬ ë³€ê²½] íŒŒì¼ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¡œë”© ë¡œì§ ---
    uploaded_file = st.file_uploader("ê·¼ë¡œê³„ì•½ì„œ PDF ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)", type=["pdf"])
    
    contract_content = ""
    
    if uploaded_file is not None:
        with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            extracted_text = extract_text_from_pdf(uploaded_file,api_key_input,'gemini-2.0-flash-lite')
            if extracted_text:
                contract_content = extracted_text
                st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
            else:
                contract_content = get_dummy_contract_text()
                st.warning("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í•˜ì—¬ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    else:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
        contract_content = get_dummy_contract_text()

    # í…ìŠ¤íŠ¸ ì—ë””í„° (ìˆ˜ì • ê°€ëŠ¥)
    # PDF ë‚´ìš©ì„ ë¶ˆëŸ¬ì™”ë”ë¼ë„ ì—¬ê¸°ì„œ ì‚¬ìš©ìê°€ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŒ
    final_text = st.text_area("ê³„ì•½ì„œ ë‚´ìš© í™•ì¸ ë° ìˆ˜ì •", value=contract_content, height=300)

    # API í‚¤ ì²´í¬
    if not os.environ.get("GEMINI_API_KEY"):
        st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    # [ë¶„ì„ ë²„íŠ¼]
    if st.button("ğŸš€ ë…ì†Œì¡°í•­ ë¶„ì„ ì‹œì‘", use_container_width=True):
        
        # 1. Parsing
        chunks = parse_text_to_chunks(final_text)
        
        if not chunks:
            st.error("ë¶„ì„í•  ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ì— 'ì œNì¡°' í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # 2. Detector ì´ˆê¸°í™” (ìºì‹±)
        @st.cache_resource
        def get_detector(key):
            return ToxicClauseDetector(key)
        
        with st.spinner("âš™ï¸ ë²•ë ¹ DB ë° AI ì—”ì§„ ì´ˆê¸°í™” ì¤‘... (ìµœì´ˆ 1íšŒë§Œ ì†Œìš”)"):
            detector = get_detector(api_key_input)

        st.info(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­ì„ ìˆœì„œëŒ€ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

        # 3. ìˆœì°¨ ì‹¤í–‰ ë£¨í”„
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, clause in enumerate(chunks):
            status_text.markdown(f"**ğŸ•µï¸ ë¶„ì„ ì¤‘ ({i+1}/{len(chunks)}):** ì œ{i+1}ì¡° ì‹¬ì‚¬ ì¤‘...")
            
            res = process_single_clause(detector, clause, i)
            results.append(res)
            
            progress_bar.progress((i + 1) / len(chunks))

        status_text.success("âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.session_state.analysis_results = results
        
        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        st.divider()
        
        # ìš”ì•½ ì§€í‘œ
        toxic_count = sum(1 for r in results if r.get('is_toxic'))
        col1, col2 = st.columns(2)
        col1.metric("ë¶„ì„ëœ ì¡°í•­", f"{len(results)}ê±´")
        col2.metric("ë°œê²¬ëœ ìœ„í—˜ ì¡°í•­", f"{toxic_count}ê±´", delta="-ì£¼ì˜" if toxic_count > 0 else "ì•ˆì „")

        # ìƒì„¸ ê²°ê³¼ íƒ­
        tab1, tab2 = st.tabs(["ğŸš¨ ìœ„í—˜ ì¡°í•­ ë¦¬í¬íŠ¸", "ğŸ“‘ ì „ì²´ ì¡°í•­ ë³´ê¸°"])
        
        with tab1:
            if toxic_count == 0:
                st.success("ë…ì†Œì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                for res in results:
                    if res.get('is_toxic'):
                        with st.expander(f"âš ï¸ [ìœ„í—˜] ì œ{res['id']}ì¡° (ìœ„í—˜ë„: {res['score']})", expanded=True):
                            c1, c2 = st.columns(2)
                            with c1:
                                st.caption("ì›ë¬¸")
                                st.error(res['clause'])
                                st.markdown(f"**íŒë‹¨ ê·¼ê±°:** {res['reason']}")
                            with c2:
                                st.caption("AI ì†”ë£¨ì…˜")
                                st.markdown(res['suggestion'])
                                with st.popover("ì°¸ê³  ë²•ë ¹ í™•ì¸"):
                                    st.text(res['context'])
        
        with tab2:
            for res in results:
                icon = "ğŸ”´" if res.get('is_toxic') else "ğŸŸ¢"
                with st.expander(f"{icon} ì œ{res['id']}ì¡°"):
                    st.write(res['clause'])
                    if 'error' in res:
                        st.error(f"ì—ëŸ¬: {res['error']}")
                    else:
                        st.caption(f"íŒë‹¨ ê²°ê³¼: {res['reason']}")

if __name__ == "__main__":
    main()