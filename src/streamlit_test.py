# Copyright (c) 2025 SafeSign
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
import streamlit as st
import re
import os
import time
from dotenv import load_dotenv

# [Import] src í´ë” ë‚´ì˜ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš” (ì˜ˆ: from src.toxic_detector import ...)
from toxic_detector import ToxicClauseDetector
from llm_service import LLM_gemini

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸° (Parallel)",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. í—¬í¼ í•¨ìˆ˜ë“¤ (PDF íŒŒì‹± & ë”ë¯¸ ë°ì´í„°) ---

def extract_text_from_pdf(pdf_file, api_key, model_name): 
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        pdf_file_bytes = pdf_file.read()   
        gemini = LLM_gemini(gemini_api_key=api_key, model=model_name)
        result = gemini.pdf_to_text(pdf_file_bytes)
        return result
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def get_dummy_contract_text():
    """í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ê·¼ë¡œê³„ì•½ì„œ í…ìŠ¤íŠ¸"""
    return """
ì œ1ì¡° (ëª©ì )
ë³¸ ê³„ì•½ì€ ì‚¬ìš©ì (ì£¼)ì•…ë•ìƒì‚¬(ì´í•˜ "ê°‘")ì™€ ê·¼ë¡œì í™ê¸¸ë™(ì´í•˜ "ì„")ì˜ ê·¼ë¡œì¡°ê±´ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.

ì œ2ì¡° (ê·¼ë¡œì¥ì†Œ ë° ì—…ë¬´)
"ì„"ì€ "ê°‘"ì˜ ë³¸ì‚¬ ë° "ê°‘"ì´ ì§€ì •í•˜ëŠ” ì¥ì†Œì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤.

ì œ3ì¡° (ê·¼ë¡œì‹œê°„)
1. ê·¼ë¡œì‹œê°„ì€ 09:00ë¶€í„° 18:00ê¹Œì§€ë¡œ í•œë‹¤ (íœ´ê²Œì‹œê°„ 1ì‹œê°„ í¬í•¨).
2. "ê°‘"ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ê²½ìš° "ì„"ì—ê²Œ ì—°ì¥, ì•¼ê°„ ë° íœ´ì¼ê·¼ë¡œë¥¼ ëª…í•  ìˆ˜ ìˆìœ¼ë©° "ì„"ì€ ì´ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.

ì œ4ì¡° (ì„ê¸ˆ)
1. ì›” ê¸‰ì—¬ëŠ” 2,500,000ì›ìœ¼ë¡œ í•œë‹¤.
2. ìœ„ ê¸‰ì—¬ì—ëŠ” ì‹ëŒ€, êµí†µë¹„ ë° ë²•ì • ì œìˆ˜ë‹¹(ì—°ì¥, ì•¼ê°„, íœ´ì¼ê·¼ë¡œìˆ˜ë‹¹ ë“±)ì´ ëª¨ë‘ í¬í•¨ëœ í¬ê´„ì„ê¸ˆìœ¼ë¡œ ì‚°ì •í•˜ë©°, "ì„"ì€ ì¶”ê°€ì ì¸ ìˆ˜ë‹¹ì„ ì²­êµ¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì œ5ì¡° (í‡´ì§ê¸ˆ)
"ì„"ì´ ì…ì‚¬ í›„ 1ë…„ ë¯¸ë§Œì— í‡´ì‚¬í•˜ëŠ” ê²½ìš°, ìˆ˜ìŠµê¸°ê°„ ë™ì•ˆì˜ êµìœ¡ë¹„ ë° ì†í•´ë°°ìƒ ëª…ëª©ìœ¼ë¡œ í‡´ì§ê¸ˆì€ ì§€ê¸‰í•˜ì§€ ì•„ë‹ˆí•œë‹¤.

ì œ6ì¡° (ê³„ì•½í•´ì§€)
"ì„"ì´ ë¬´ë‹¨ê²°ê·¼ 3ì¼ ì´ìƒ ì§€ì†í•˜ê±°ë‚˜ ì—…ë¬´ ëŠ¥ë ¥ì´ í˜„ì €íˆ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë  ê²½ìš° "ê°‘"ì€ ì¦‰ì‹œ ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆë‹¤.

ì œ7ì¡° (ì†í•´ë°°ìƒ)
"ì„"ì´ ê³„ì•½ê¸°ê°„ ì¤‘ í‡´ì‚¬í•˜ì—¬ "ê°‘"ì—ê²Œ ì†í•´ë¥¼ ì…íŒ ê²½ìš°, "ì„"ì€ "ê°‘"ì—ê²Œ ì¼ê¸ˆ 1,000ë§Œì›ì„ ë°°ìƒí•˜ì—¬ì•¼ í•œë‹¤.
"""

def parse_text_to_chunks(text):
    """í…ìŠ¤íŠ¸ë¥¼ 'ì œNì¡°' ê¸°ì¤€ìœ¼ë¡œ ìë¥´ëŠ” íŒŒì„œ"""
    if not text:
        return []
    split_pattern = r'(?=\n\s*ì œ\s*\d+\s*ì¡°)'
    chunks = re.split(split_pattern, text)
    # ê³µë°± ì œê±° ë° ìœ íš¨í•œ ì¡°í•­ë§Œ í•„í„°ë§ (ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ì€ ì œì™¸)
    clean_chunks = [c.strip() for c in chunks if len(c.strip()) > 10]
    return clean_chunks

# --- 3. ë©”ì¸ ì–´í”Œë¦¬ì¼€ì´ì…˜ --- 
def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("âš–ï¸ Contract Guardian")
        st.caption("Parallel Processing Edition")
        st.markdown("---")
        
        load_dotenv()
        env_key = os.getenv("GEMINI_API_KEY")
        
        api_key_input = st.text_input(
            "Gemini API Key", 
            value=env_key if env_key else "", 
            type="password"
        )
        if api_key_input:
            os.environ["GEMINI_API_KEY"] = api_key_input

        st.info("ğŸ’¡ PDF íŒŒì¼ì„ ì˜¬ë¦¬ë©´ í•´ë‹¹ ë‚´ìš©ì„, ì˜¬ë¦¬ì§€ ì•Šìœ¼ë©´ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    # ë©”ì¸ í™”ë©´
    st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸°")
    st.markdown("ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ **ë³‘ë ¬ ì²˜ë¦¬(Parallel Processing)**ë¥¼ í†µí•´ ì‹ ì†í•˜ê²Œ ë…ì†Œì¡°í•­ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.")

    # íŒŒì¼ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¡œë”©
    uploaded_file = st.file_uploader("ê·¼ë¡œê³„ì•½ì„œ PDF ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)", type=["pdf"])
    
    contract_content = ""
    
    if uploaded_file is not None:
        with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            extracted_text = extract_text_from_pdf(uploaded_file, api_key_input, 'gemini-1.5-flash')
            if extracted_text:
                contract_content = extracted_text
                st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
            else:
                contract_content = get_dummy_contract_text()
                st.warning("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        contract_content = get_dummy_contract_text()

    # í…ìŠ¤íŠ¸ ì—ë””í„°
    final_text = st.text_area("ê³„ì•½ì„œ ë‚´ìš© í™•ì¸ ë° ìˆ˜ì •", value=contract_content, height=300)

    # API í‚¤ ì²´í¬
    if not os.environ.get("GEMINI_API_KEY"):
        st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    # [ë¶„ì„ ë²„íŠ¼]
    if st.button("ğŸš€ ë…ì†Œì¡°í•­ ê³ ì† ë¶„ì„ ì‹œì‘", use_container_width=True):
        
        # 1. Parsing
        chunks = parse_text_to_chunks(final_text)
        
        if not chunks:
            st.error("ë¶„ì„í•  ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ì— 'ì œNì¡°' í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # 2. Detector ì´ˆê¸°í™” (ìºì‹±)
        @st.cache_resource
        def get_detector(key):
            return ToxicClauseDetector(key)
        
        with st.spinner("âš™ï¸ AI ì—”ì§„ ë° ë²•ë¥  DB ë¡œë”© ì¤‘..."):
            detector = get_detector(api_key_input)

        st.info(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

        # --- [í•µì‹¬ ë³€ê²½] ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ---
        try:
            start_time = time.time()
            
            # DeepEvalì˜ evaluate í•¨ìˆ˜ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
            # ë£¨í”„ë¥¼ ëŒë¦¬ì§€ ì•Šê³  ë¦¬ìŠ¤íŠ¸ ì „ì²´ë¥¼ ë„˜ê¹ë‹ˆë‹¤.
            raw_results = detector.detect(chunks, max_concurrent=5)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

        # 3. ê²°ê³¼ í›„ì²˜ë¦¬ (ID ë¶€ì—¬ ë° ê°œì„ ì•ˆ ìƒì„±)
        processed_results = []
        toxic_indices = [] # ê°œì„ ì•ˆ ìƒì„±ì´ í•„ìš”í•œ ì¸ë±ìŠ¤ë“¤
        
        # 3-1. ê¸°ë³¸ ê²°ê³¼ ë§¤í•‘
        for i, res in enumerate(raw_results):
            # detect í•¨ìˆ˜ì—ì„œ ë‚˜ì˜¨ ê²°ê³¼ì— ID(ì¡°í•­ ë²ˆí˜¸) ì¶”ê°€
            res['id'] = i + 1
            res['suggestion'] = "" # ì´ˆê¸°í™”
            processed_results.append(res)
            
            if res['is_toxic']:
                toxic_indices.append(i)

        # 3-2. ê°œì„ ì•ˆ ìƒì„± (ìœ„í—˜í•œ ì¡°í•­ë§Œ ìˆœì°¨/ë³‘ë ¬ ì²˜ë¦¬)
        # í‰ê°€ëŠ” ë¹¨ë¼ë„ ìƒì„±(Suggestion)ì€ ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ ì§„í–‰ìƒí™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        if toxic_indices:
            suggestion_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, list_idx in enumerate(toxic_indices):
                status_text.text(f"ğŸ’¡ ìœ„í—˜ ì¡°í•­({processed_results[list_idx]['id']}ì¡°)ì— ëŒ€í•œ ê°œì„ ì•ˆì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
                
                # í•´ë‹¹ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                target_result = processed_results[list_idx]
                
                # ê°œì„ ì•ˆ ìƒì„± í˜¸ì¶œ
                try:
                    suggestion = detector.generate_easy_suggestion(target_result)
                    processed_results[list_idx]['suggestion'] = suggestion
                except Exception as e:
                    processed_results[list_idx]['suggestion'] = "ê°œì„ ì•ˆ ìƒì„± ì‹¤íŒ¨"
                
                suggestion_bar.progress((idx + 1) / len(toxic_indices))
            
            status_text.empty()
            suggestion_bar.empty()

        st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        
        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        st.divider()
        
        # ìš”ì•½ ì§€í‘œ
        toxic_count = len(toxic_indices)
        col1, col2 = st.columns(2)
        col1.metric("ë¶„ì„ëœ ì¡°í•­", f"{len(chunks)}ê±´")
        col2.metric("ë°œê²¬ëœ ìœ„í—˜ ì¡°í•­", f"{toxic_count}ê±´", delta="-ì£¼ì˜" if toxic_count > 0 else "ì•ˆì „")

        # ìƒì„¸ ê²°ê³¼ íƒ­
        tab1, tab2 = st.tabs(["ğŸš¨ ìœ„í—˜ ì¡°í•­ ë¦¬í¬íŠ¸", "ğŸ“‘ ì „ì²´ ì¡°í•­ ë³´ê¸°"])
        
        with tab1:
            if toxic_count == 0:
                st.balloons()
                st.success("ì™„ë²½í•©ë‹ˆë‹¤! ë…ì†Œì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                for res in processed_results:
                    if res.get('is_toxic'):
                        # ìœ„í—˜ë„ì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„ (ì„ íƒì‚¬í•­)
                        risk_label = "ì¹˜ëª…ì " if res['risk_score'] >= 9 else "ìœ„í—˜"
                        
                        with st.expander(f"âš ï¸ [{risk_label}] ì œ{res['id']}ì¡° (ìœ„í—˜ë„: {res['risk_score']})", expanded=True):
                            c1, c2 = st.columns(2)
                            with c1:
                                st.caption("âŒ ì›ë¬¸ ì¡°í•­")
                                st.error(res['clause'])
                                st.markdown(f"**ğŸ” íŒë‹¨ ê·¼ê±°:**\n{res['reason']}")
                            with c2:
                                st.caption("ğŸ’¡ AI ìˆ˜ì • ì œì•ˆ")
                                if res['suggestion']:
                                    st.markdown(res['suggestion'])
                                else:
                                    st.info("ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
                                
                                with st.popover("ğŸ“œ ì°¸ê³  ë²•ë ¹/íŒë¡€ ë³´ê¸°"):
                                    st.text(res['context_used'])
        
        with tab2:
            st.caption("ëª¨ë“  ì¡°í•­ì— ëŒ€í•œ AIì˜ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.")
            for res in processed_results:
                icon = "ğŸ”´" if res.get('is_toxic') else "ğŸŸ¢"
                score_badge = f"(ì ìˆ˜: {res['risk_score']})"
                
                with st.expander(f"{icon} ì œ{res['id']}ì¡° {score_badge}"):
                    st.code(res['clause'], language="text")
                    st.write(f"**íŒë‹¨:** {res['reason']}")

if __name__ == "__main__":
    main()