import os
import time
from datasets import load_dataset
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings # Deprecation ê²½ê³ ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ìˆ˜ì •
from langchain_core.documents import Document

# --- ì„¤ì • ---
# â­ï¸ DB_PATHë¥¼ íŒë¡€ ì „ìš©ìœ¼ë¡œ ë³€ê²½
DB_PATH = "../data/faiss_precedent_db" 
EMBEDDING_MODEL_NAME = "jhgan/ko-sbert-nli" # ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
# â­ï¸ íŒë¡€ ë°ì´í„°ì…‹ ID
DATASET_ID = "joonhok-exo-ai/korean_law_open_data_precedents" 
SAMPLE_SIZE = 1000 # í…ŒìŠ¤íŠ¸/êµ¬ì¶•ìš© ë°ì´í„° ê°œìˆ˜ (ì „ì²´ ì‚¬ìš© ì‹œ None)

class PrecedentContextManager:
    """
    íŒë¡€ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„° DBë¥¼ êµ¬ì¶•í•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        self.vectorstore = None
        # ì„ë² ë”© ëª¨ë¸ ê°ì²´ëŠ” í•œ ë²ˆë§Œ ìƒì„±
        self.embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
        # âš ï¸ ì°¸ê³ : self.embeddings ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    def create_database(self):
        """
        Hugging Face ë°ì´í„°ì…‹ì—ì„œ íŒë¡€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  Document ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ“¥ íŒë¡€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... ({DATASET_ID})")
        
        try:
            dataset = load_dataset(DATASET_ID, split="train") 
            
            if SAMPLE_SIZE and len(dataset) > SAMPLE_SIZE:
                dataset = dataset.select(range(SAMPLE_SIZE)) 
                print(f"    - (ì„¤ì •) ìƒìœ„ {SAMPLE_SIZE}ê°œë§Œ ë²¡í„°í™”í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
        
        print("ğŸ”„ ë¬¸ì„œ ê°ì²´(Document)ë¡œ ë³€í™˜ ì¤‘...")
        documents = []

        for item in dataset:
            # ë°ì´í„°ì…‹ ì»¬ëŸ¼ ë§¤í•‘
            content = item.get('ì „ë¬¸', '')
            summary = item.get('íŒê²°ìš”ì§€', '')
            case_name = item.get('ì‚¬ê±´ëª…', 'ì‚¬ê±´ëª… ì •ë³´ ì—†ìŒ')
            case_number = item.get('ì‚¬ê±´ë²ˆí˜¸', 'N/A')

            # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•œ page_content êµ¬ì„±
            page_content = f"""
[ì‚¬ê±´ë²ˆí˜¸] {case_number}
[ì‚¬ê±´ëª…] {case_name}
[íŒê²°ìš”ì§€] {summary}
[ì „ë¬¸] {content[:2000]}...
""".strip()
            
            metadata = {
                "case_name": case_name, 
                "source": "HuggingFace Precedent DB",
                "case_number": case_number
            }
            
            if len(summary) > 10: # ìš”ì§€ê°€ ì§§ì€ ë°ì´í„°ëŠ” ì œì™¸
                 documents.append(Document(page_content=page_content, metadata=metadata))
        
        print(f"    - ë³€í™˜ëœ ìœ íš¨ ë¬¸ì„œ: {len(documents)}ê°œ")
        return documents

    def initialize_database(self):
        """
        ë¡œì»¬ DB ê²½ë¡œë¥¼ í™•ì¸í•˜ì—¬ DBë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ êµ¬ì¶• í›„ ì €ì¥í•©ë‹ˆë‹¤.
        """
        if self.vectorstore is not None:
            print("ğŸ’¡ íŒë¡€ DBê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        # 1. ë¡œì»¬ DB íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ë¡œë“œ
        if os.path.exists(DB_PATH) and os.path.isdir(DB_PATH):
            print(f"âœ… [ì´ˆê¸°í™”] ê¸°ì¡´ íŒë¡€ DB ë¡œë“œ ì¤‘... (ê²½ë¡œ: {DB_PATH})")
            try:
                # ë¡œì»¬ DB ë¡œë“œ (allow_dangerous_deserialization=True ì„¤ì •)
                self.vectorstore = FAISS.load_local(
                    DB_PATH, 
                    self.embeddings, 
                    allow_dangerous_deserialization=True
                )
                print(f"âœ… [ì´ˆê¸°í™”] íŒë¡€ DB ë¡œë“œ ì™„ë£Œ! (ì´ {len(self.vectorstore.docstore._dict)}ê±´)")
                return
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ DB ë¡œë“œ ì‹¤íŒ¨: {e}. DBë¥¼ ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")
        
        # 2. ì‹ ê·œ DB êµ¬ì¶•
        print("ğŸ“š [ì´ˆê¸°í™”] íŒë¡€ ë°ì´í„° ì‹ ê·œ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        all_docs = self.create_database()

        if not all_docs:
            print("âŒ ì €ì¥í•  íŒë¡€ ë°ì´í„°ê°€ ì—†ì–´ DB ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # 3. ë²¡í„° DB ìƒì„± ë° ë¡œì»¬ ì €ì¥
        print(f"âš¡ ì´ {len(all_docs)}ê°œ íŒë¡€ ë²¡í„°í™” ë° DB ì €ì¥ ì‹œì‘...")
        start_time = time.time()
        
        self.vectorstore = FAISS.from_documents(all_docs, self.embeddings)
        
        # ë¡œì»¬ ì €ì¥
        os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
        self.vectorstore.save_local(DB_PATH)
        
        elapsed_time = time.time() - start_time
        print(f"âœ… íŒë¡€ DB ì‹ ê·œ êµ¬ì¶• ë° ì €ì¥ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ, ê²½ë¡œ: {os.path.abspath(DB_PATH)})")
        
    def search_relevant_precedents(self, query, k=2):
        """
        ë¡œì»¬ì— ë¡œë“œëœ DBì—ì„œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ íŒë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        :param query: ê²€ìƒ‰ì„ ìœ„í•œ ì‚¬ìš©ì ì§ˆë¬¸(í…ìŠ¤íŠ¸)
        :param k: ë°˜í™˜í•  ê²€ìƒ‰ ê²°ê³¼(Document)ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤. (ê¸°ë³¸ê°’: 2)
        :return: ê²€ìƒ‰ëœ íŒë¡€ ë‚´ìš©(page_content) ë¦¬ìŠ¤íŠ¸
        """
        # DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if not self.vectorstore:
            self.initialize_database()
        
        if not self.vectorstore:
            print("âš ï¸ íŒë¡€ DBê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        print(f"ğŸ” íŒë¡€ DBì—ì„œ '{query[:20]}...' ê´€ë ¨ íŒë¡€ {k}ê°œ ê²€ìƒ‰ ì¤‘...")
        # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
        docs = self.vectorstore.similarity_search(query, k=k)
        
        # 
        
        return [doc.page_content for doc in docs]

# ==========================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ==========================================
if __name__ == "__main__":
    # DB ì €ì¥ ê²½ë¡œ ìƒì„±
    if not os.path.exists(os.path.dirname(DB_PATH)):
        os.makedirs(os.path.dirname(DB_PATH))

    manager = PrecedentContextManager()
    
    # DBê°€ ì—†ìœ¼ë©´ êµ¬ì¶•í•˜ê³ , ìˆìœ¼ë©´ ë¡œë“œí•©ë‹ˆë‹¤.
    manager.initialize_database()
    
    # êµ¬ì¶•ëœ DBë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    question = "ì§ì›ì´ ì—…ë¬´ íƒœë§Œìœ¼ë¡œ í•´ê³ ë˜ì—ˆì„ ë•Œ ë¶€ë‹¹ í•´ê³ ë¡œ ì¸ì •ë  ìˆ˜ ìˆëŠ” ê¸°ì¤€ì´ ë­ì•¼?"
    relevant_cases = manager.search_relevant_precedents(question, k=1)
    
    print("\n" + "="*50)
    print("ğŸ“ ê²€ìƒ‰ëœ ìœ ì‚¬ íŒë¡€:")
    print("="*50)
    
    if relevant_cases:
        print(relevant_cases[0])
    else:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")