import streamlit as st
import time
import pandas as pd
from datetime import datetime

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(
    page_title="ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸° (AI Guardian)",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# [Role C, B, A] Backend Mock Modules
# ì‹¤ì œ ê°œë°œ ì‹œ src/ í´ë”ì˜ ëª¨ë“ˆì„ import í•´ì•¼ í•¨
# ==========================================

# [Role C] src.parser.pdf_parser & text_chunker
def mock_parser(uploaded_file):
    """
    [TODO: Role C] ì‹¤ì œ PDF íŒŒì‹± ë° Regex Chunking ë¡œì§ êµ¬í˜„
    """
    time.sleep(1) # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
    return [
        "ì œ1ì¡° (ëª©ì ) ë³¸ ê³„ì•½ì€ ì‚¬ìš©ìì™€ ê·¼ë¡œìì˜ ê·¼ë¡œì¡°ê±´ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.",
        "ì œ2ì¡° (ì„ê¸ˆ) ì›” ê¸‰ì—¬ëŠ” 200ë§Œì›ìœ¼ë¡œ í•˜ë©°, ì´ëŠ” ì—°ì¥ê·¼ë¡œìˆ˜ë‹¹ì„ í¬í•¨í•œ í¬ê´„ì„ê¸ˆìœ¼ë¡œ í•œë‹¤.", # ë…ì†Œì¡°í•­ ì˜ˆì‹œ
        "ì œ3ì¡° (ê·¼ë¡œì‹œê°„) ê·¼ë¡œì‹œê°„ì€ 09:00ë¶€í„° 18:00ê¹Œì§€ë¡œ í•œë‹¤.",
        "ì œ4ì¡° (í‡´ì§ê¸ˆ) 1ë…„ ë¯¸ë§Œ ê·¼ë¬´ í›„ í‡´ì‚¬ ì‹œ í‡´ì§ê¸ˆì€ ì§€ê¸‰í•˜ì§€ ì•Šìœ¼ë©° ì†í•´ë°°ìƒì„ ì²­êµ¬í•œë‹¤." # ë…ì†Œì¡°í•­ ì˜ˆì‹œ
    ]

# [Role C] src.retriever.law_api & case_search
def mock_retriever(clause_text):
    """
    [TODO: Role C] ë²•ì œì²˜ API ë° HuggingFace Vector DB ê²€ìƒ‰ êµ¬í˜„
    """
    return {
        "law": "ê·¼ë¡œê¸°ì¤€ë²• ì œNì¡°...",
        "case": "ëŒ€ë²•ì› 20XXë‹¤XXXX íŒê²°..."
    }

# [Role B] src.evaluator.g_eval & faithfulness
def mock_evaluator(clause, context):
    """
    [TODO: Role B] DeepEval G-Eval ë° Faithfulness Metric êµ¬í˜„
    """
    # ë…ì†Œì¡°í•­ ì‹œë®¬ë ˆì´ì…˜ (íŠ¹ì • í‚¤ì›Œë“œë¡œ êµ¬ë¶„)
    if "í¬ê´„ì„ê¸ˆ" in clause or "ì†í•´ë°°ìƒ" in clause:
        return {
            "score": 8, # ìœ„í—˜ë„ 1~10
            "is_toxic": True,
            "reason": "í¬ê´„ì„ê¸ˆì œ ì˜¤ë‚¨ìš© ë° ìœ„ì•½ê¸ˆ ì˜ˆì • ê¸ˆì§€ ì¡°í•­ ìœ„ë°˜ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.",
            "faithfulness": 0.95
        }
    else:
        return {
            "score": 1,
            "is_toxic": False,
            "reason": "ë²•ì  ë¬¸ì œ ì—†ìŒ.",
            "faithfulness": 1.0
        }

# [Role A] src.generator.report_gen
def mock_generator(clause, evaluation):
    """
    [TODO: Role A] LLMì„ ì´ìš©í•œ ì‰¬ìš´ í•´ì„ ë° ìˆ˜ì • ì œì•ˆ ìƒì„±
    """
    if evaluation["is_toxic"]:
        return "ì´ ì¡°í•­ì€ ë‹¹ì‹ ì´ ì•¼ê·¼ì„ í•´ë„ ì¶”ê°€ ìˆ˜ë‹¹ì„ ë°›ê¸° ì–´ë µê²Œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”. 'í¬ê´„ì„ê¸ˆ'ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì£¼ì˜í•˜ì„¸ìš”."
    return "í‘œì¤€ì ì¸ ê·¼ë¡œê³„ì•½ ì¡°í•­ì…ë‹ˆë‹¤. ì•ˆì‹¬í•˜ì…”ë„ ë©ë‹ˆë‹¤."

# ==========================================
# [Role D] Frontend UI Logic
# ==========================================

def main():
    # 1. ì‚¬ì´ë“œë°”: ì„¤ì • ë° íŒŒì¼ ì—…ë¡œë“œ
    with st.sidebar:
        st.title("âš–ï¸ AI Contract Guardian")
        st.markdown("---")
        
        st.subheader("1. ì„¤ì •")
        api_key = st.text_input("OpenAI/Gemini API Key", type="password")
        
        st.subheader("2. ê³„ì•½ì„œ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ê·¼ë¡œê³„ì•½ì„œ(PDF/IMG)ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”", type=["pdf", "png", "jpg"])
        
        st.markdown("---")
        st.info("ğŸ’¡ ì´ ë„êµ¬ëŠ” ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©° ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")

    # 2. ë©”ì¸ í™”ë©´: í—¤ë”
    st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸°")
    st.markdown("""
    **RAGì™€ DeepEval**ì„ í™œìš©í•˜ì—¬ ê³„ì•½ì„œ ë‚´ ìˆ¨ê²¨ì§„ **ë…ì†Œì¡°í•­(Toxic Clause)**ì„ ì°¾ì•„ë‚´ê³ , 
    ì´í•´í•˜ê¸° ì‰¬ìš´ **í•´ì„¤**ì„ ì œê³µí•©ë‹ˆë‹¤.
    """)

    # 3. ë¶„ì„ ë¡œì§ ì‹¤í–‰
    if uploaded_file is not None:
        st.success("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        if st.button("ğŸš€ ë…ì†Œì¡°í•­ ë¶„ì„ ì‹œì‘", use_container_width=True):
            
            # [Step 1] Parsing
            with st.status("ğŸ” ê³„ì•½ì„œë¥¼ ì½ê³  ì¡°í•­ì„ ë‚˜ëˆ„ëŠ” ì¤‘...", expanded=True) as status:
                st.write("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
                chunks = mock_parser(uploaded_file)
                st.write(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­ì´ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                time.sleep(0.5)
                
                # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
                results = []
                
                # [Step 2] Analysis Loop (Progress Bar)
                progress_bar = st.progress(0)
                
                for i, clause in enumerate(chunks):
                    # UI ì—…ë°ì´íŠ¸
                    status.update(label=f"íŒë³„ ì¤‘... ({i+1}/{len(chunks)}): ì œ{i+1}ì¡° ë¶„ì„", state="running")
                    
                    # RAG & DeepEval Pipeline Execution
                    context = mock_retriever(clause)
                    eval_result = mock_evaluator(clause, context)
                    easy_explanation = mock_generator(clause, eval_result)
                    
                    results.append({
                        "id": i+1,
                        "clause": clause,
                        "score": eval_result["score"],
                        "is_toxic": eval_result["is_toxic"],
                        "reason": eval_result["reason"],
                        "explanation": easy_explanation,
                        "faithfulness": eval_result["faithfulness"]
                    })
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    progress_bar.progress((i + 1) / len(chunks))
                    time.sleep(0.5) # ì‹¤ì œ ì†ë„ì— ë§ì¶° ì¡°ì •

                status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

            # 4. ê²°ê³¼ ëŒ€ì‹œë³´ë“œ (Session Stateì— ì €ì¥í•˜ì—¬ ë¦¬ë Œë”ë§ ë°©ì§€ ê°€ëŠ¥)
            st.divider()
            st.subheader("ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸")

            # ìš”ì•½ ì§€í‘œ
            toxic_count = sum(1 for r in results if r["is_toxic"])
            col1, col2, col3 = st.columns(3)
            col1.metric("ì´ ì¡°í•­ ìˆ˜", f"{len(chunks)}ê°œ")
            col2.metric("ë°œê²¬ëœ ë…ì†Œì¡°í•­", f"{toxic_count}ê°œ", delta="-ìœ„í—˜" if toxic_count > 0 else "ì•ˆì „")
            col3.metric("í‰ê·  ì‹ ë¢°ë„(Faithfulness)", "0.98")

            # ìƒì„¸ ê²°ê³¼ ë·°ì–´
            st.markdown("### ğŸ“ ìƒì„¸ ì¡°í•­ ë¶„ì„")
            
            tab1, tab2 = st.tabs(["ğŸš¨ ìœ„í—˜ ì¡°í•­ë§Œ ë³´ê¸°", "ğŸ“‘ ì „ì²´ ì¡°í•­ ë³´ê¸°"])
            
            with tab1:
                if toxic_count == 0:
                    st.success("ë…ì†Œì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                else:
                    for res in results:
                        if res["is_toxic"]:
                            with st.expander(f"âš ï¸ [ìœ„í—˜] ì œ{res['id']}ì¡° ë¶„ì„ ê²°ê³¼ (ìœ„í—˜ë„: {res['score']}/10)", expanded=True):
                                st.markdown(f"**ì›ë¬¸:**\n> {res['clause']}")
                                st.error(f"**íŒë‹¨ ê·¼ê±°:** {res['reason']}")
                                st.info(f"**ğŸ’¡ ì‰¬ìš´ í•´ì„:** {res['explanation']}")
                                st.caption(f"AI ì‹ ë¢°ë„ ê²€ì¦: {res['faithfulness']}")

            with tab2:
                for res in results:
                    icon = "ğŸ”´" if res['is_toxic'] else "ğŸŸ¢"
                    title = f"{icon} ì œ{res['id']}ì¡°"
                    with st.expander(title):
                        st.write(res['clause'])
                        if res['is_toxic']:
                             st.warning(res['explanation'])
                        else:
                             st.success("ì•ˆì „í•œ ì¡°í•­ì…ë‹ˆë‹¤.")

    else:
        # íŒŒì¼ì´ ì—†ì„ ë•Œ ë³´ì—¬ì¤„ ì•ˆë‚´ í™”ë©´
        st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ê³„ì•½ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        #  
        # (ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” assets/sample.png ì´ë¯¸ì§€ë¥¼ ë¡œë“œ)

if __name__ == "__main__":
    main()